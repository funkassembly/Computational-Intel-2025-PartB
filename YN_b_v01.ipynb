{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "239d1b37-5bd3-4477-87b0-197293cc3d86",
   "metadata": {},
   "source": [
    "# YN Μέρος Β"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db60db5-2e8d-4c48-a07e-b5aaa7a15749",
   "metadata": {},
   "source": [
    "## Β1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eac09e2-2346-4047-85b0-276d35e296a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\ml-env\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e631059-3c96-45be-9a37-f2bdd1338590",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"alzheimers_disease_data.csv\"  \n",
    "TARGET = \"Diagnosis\"                      \n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "ID_LIKE_COLS = [\"PatientID\", \"DoctorInCharge\", \"SubjectID\", \"MRI_ID\", \"ID\"]\n",
    "for col in ID_LIKE_COLS:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET}' not found. Update TARGET to your dataset.\")\n",
    "y = df[TARGET].astype(int)\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "cat_cols = list(X.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns)\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c19d00d-17d4-448c-b853-a4ee34254a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_val_raw, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0e0ad68-ecf7-48d1-862a-1b778283f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipe = Pipeline([('scaler', StandardScaler())])\n",
    "cat_pipe = Pipeline([('ohe', OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipe, num_cols),\n",
    "        ('cat', cat_pipe, cat_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit on TRAIN only (no leakage), then transform both\n",
    "X_train_tr = preprocessor.fit_transform(X_train_raw)\n",
    "X_val_tr   = preprocessor.transform(X_val_raw)\n",
    "\n",
    "X_train_tr = np.asarray(X_train_tr)\n",
    "X_val_tr   = np.asarray(X_val_tr)\n",
    "\n",
    "input_dim = X_train_tr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22bb408-476c-44bd-a3f4-f6b9ed0b68e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_best_model(input_dim):\n",
    "    #A5 best was [I, I] with ReLU + SGD(lr=0.1, m=0.6)\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_dim,)))\n",
    "    model.add(Dense(input_dim, activation='relu'))  \n",
    "    model.add(Dense(input_dim, activation='relu'))  \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=SGD(learning_rate=0.1, momentum=0.6),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_best_model(input_dim)\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "_ = model.fit(\n",
    "    X_train_tr, y_train,\n",
    "    validation_data=(X_val_tr, y_val),\n",
    "    epochs=200, verbose=0, callbacks=[early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5131a445-3ea4-49a0-8915-1201655dd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_column_groups(preprocessor, num_cols, cat_cols):\n",
    "    try:\n",
    "        names = preprocessor.get_feature_names_out()\n",
    "    except AttributeError:\n",
    "        raise RuntimeError(\n",
    "            \"preprocessor.get_feature_names_out() not available. \"\n",
    "            \"Ensure scikit-learn >= 1.0 and that preprocessor is FIT.\"\n",
    "        )\n",
    "    column_groups = []\n",
    "    feature_names = []\n",
    "\n",
    "    def idx_where(pred):\n",
    "        return np.array([i for i, nm in enumerate(names) if pred(nm)], dtype=int)\n",
    "\n",
    "    for feat in num_cols:\n",
    "        idx = idx_where(lambda nm, f=feat: nm == f\"num__{f}\")\n",
    "        if idx.size == 0:\n",
    "            idx = idx_where(lambda nm, f=feat: nm.startswith(\"num__\") and nm.endswith(f))\n",
    "        column_groups.append(idx)\n",
    "        feature_names.append(feat)\n",
    "\n",
    "    for feat in cat_cols:\n",
    "        idx = idx_where(lambda nm, f=feat: nm.startswith(f\"cat__{f}_\") or nm == f\"cat__{f}\")\n",
    "        column_groups.append(idx)  \n",
    "        feature_names.append(feat)\n",
    "\n",
    "    return column_groups, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70b1915c-61c3-41ac-9c69-1be10fcbe361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features for GA (after A1 cleaning): 32\n",
      "Age: transformed cols [0]\n",
      "Gender: transformed cols [1]\n",
      "Ethnicity: transformed cols [2]\n",
      "EducationLevel: transformed cols [3]\n",
      "BMI: transformed cols [4]\n",
      "Smoking: transformed cols [5]\n",
      "AlcoholConsumption: transformed cols [6]\n",
      "PhysicalActivity: transformed cols [7]\n",
      "DietQuality: transformed cols [8]\n",
      "SleepQuality: transformed cols [9]\n",
      "FamilyHistoryAlzheimers: transformed cols [10]\n",
      "CardiovascularDisease: transformed cols [11]\n",
      "Diabetes: transformed cols [12]\n",
      "Depression: transformed cols [13]\n",
      "HeadInjury: transformed cols [14]\n",
      "Hypertension: transformed cols [15]\n",
      "SystolicBP: transformed cols [16]\n",
      "DiastolicBP: transformed cols [17]\n",
      "CholesterolTotal: transformed cols [18]\n",
      "CholesterolLDL: transformed cols [19]\n",
      "CholesterolHDL: transformed cols [20]\n",
      "CholesterolTriglycerides: transformed cols [21]\n",
      "MMSE: transformed cols [22]\n",
      "FunctionalAssessment: transformed cols [23]\n",
      "MemoryComplaints: transformed cols [24]\n",
      "BehavioralProblems: transformed cols [25]\n",
      "ADL: transformed cols [26]\n",
      "Confusion: transformed cols [27]\n",
      "Disorientation: transformed cols [28]\n",
      "PersonalityChanges: transformed cols [29]\n",
      "DifficultyCompletingTasks: transformed cols [30]\n",
      "Forgetfulness: transformed cols [31]\n"
     ]
    }
   ],
   "source": [
    "column_groups, original_feature_names = build_column_groups(preprocessor, num_cols, cat_cols)\n",
    "n_features = len(column_groups)\n",
    "print(f\"Original features for GA (after A1 cleaning): {n_features}\")\n",
    "\n",
    "for name, grp in zip(original_feature_names, column_groups):\n",
    "     print(f\"{name}: transformed cols {grp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52855221-53da-48ea-a285-fa51bf7c7663",
   "metadata": {},
   "source": [
    "### B1α, Β1β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3a1456e-4dbc-4c6f-bf0f-ad2234784141",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def create_chromosome(n_features):\n",
    "    # binary vector with at least one '1'\n",
    "    while True:\n",
    "        ch = rng.integers(0, 2, size=n_features, dtype=int)\n",
    "        if ch.sum() > 0:\n",
    "            return ch\n",
    "\n",
    "def initialize_population(pop_size, n_features):\n",
    "    return np.vstack([create_chromosome(n_features) for _ in range(pop_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fff5c4-6019-4f4f-96de-7c34562d5767",
   "metadata": {},
   "source": [
    "### Β1γ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fde6dcf7-1cb7-411d-b060-e61dab8c4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_mask(X_tr, chromosome, column_groups):\n",
    "\n",
    "    X_masked = X_tr.copy()\n",
    "    for gene, cols in zip(chromosome, column_groups):\n",
    "        if gene == 0 and cols.size > 0:\n",
    "            X_masked[:, cols] = 0.0\n",
    "    return X_masked\n",
    "\n",
    "def evaluate_chromosome(model, X_val_tr, y_val, chromosome, column_groups):\n",
    "   \n",
    "    if chromosome.sum() == 0:\n",
    "        return np.inf, 0.0\n",
    "    X_masked = apply_feature_mask(X_val_tr, chromosome, column_groups)\n",
    "    y_prob = model.predict(X_masked, verbose=0).ravel()\n",
    "    ce = log_loss(y_val, y_prob, labels=[0, 1])\n",
    "    acc = accuracy_score(y_val, (y_prob >= 0.5).astype(int))\n",
    "    return ce, acc\n",
    "\n",
    "def chromosome_fitness(chromosome, lam=0.05):\n",
    "    \n",
    "    ce, acc = evaluate_chromosome(model, X_val_tr, y_val, chromosome, column_groups)\n",
    "    k = int(chromosome.sum())\n",
    "    n = len(chromosome)\n",
    "    fitness = ce + lam * (k / n)\n",
    "    return fitness, {\"CE\": ce, \"Acc\": acc, \"k\": k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13e33b4c-74e5-4da2-830c-c8cb6bc387fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo chromosome: {'fitness': 0.6436, 'CE': 0.6155, 'Acc': 0.7268, 'k': 18}\n"
     ]
    }
   ],
   "source": [
    "demo_ch = create_chromosome(n_features)\n",
    "fit_val, meta = chromosome_fitness(demo_ch, lam=0.05)\n",
    "print(\"Demo chromosome:\",\n",
    "      {\"fitness\": round(fit_val, 4), \"CE\": round(meta[\"CE\"], 4),\n",
    "       \"Acc\": round(meta[\"Acc\"], 4), \"k\": meta[\"k\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0519635-e77f-4e1b-af6f-273830eacd47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
